########################################################################
#...Prompt that generated this program:
"""
Code is from an interactive session;
prompt still under development.
"""

########################################################################
#...Pseudocode for this program:
"""
# Parse command-line arguments
DEFINE parser AS ArgumentParser()
ADD argument "stats_file" (filename for training statistics)
ADD argument "model_file" (filename for saving trained classifier)
PARSE arguments

# Load extracted feature dataset from STDIN
SET feature_df = READ_CSV(STDIN, separator="\t")

# Extract feature columns and labels
SET X = feature_df EXCLUDING columns ["sampleID", "label"]
SET y = feature_df["label"]

# Split dataset into training (80%) and testing (20%) sets
SET (X_train, X_test, y_train, y_test) = TRAIN_TEST_SPLIT(X, y, test_size=0.20, stratify=y, random_seed=42)

# Initialize Random Forest Classifier
SET clf = RANDOM_FOREST(n_estimators=100, class_weight="balanced", random_seed=42)

# Perform 5-fold cross-validation on training set
SET cv_scores = CROSS_VAL_SCORE(clf, X_train, y_train, cv=5, scoring="roc_auc")

# Train classifier on full training set
TRAIN clf WITH (X_train, y_train)

# Evaluate model performance on test set
SET y_pred = PREDICT clf WITH X_test
SET test_accuracy = ACCURACY_SCORE(y_test, y_pred)
SET test_auc = ROC_AUC_SCORE(y_test, PREDICT_PROBA clf WITH X_test)

# Save training statistics to file
OPEN args.stats_file AS FILE f
    WRITE f "Cross-Validation AUC: MEAN(cv_scores) ± STD(cv_scores)"
    WRITE f "Test Accuracy: test_accuracy"
    WRITE f "Test AUC-ROC: test_auc"
CLOSE FILE f

# Save trained classifier model as a pickle file
OPEN args.model_file AS FILE f (WRITE_BINARY_MODE)
    SERIALIZE clf INTO f
CLOSE FILE f

# Print completion messages
PRINT "Training statistics saved to args.stats_file"
PRINT "Model saved to args.model_file"
"""

########################################################################
#...Code generated by Grimoire:
import sys
import argparse
import pandas as pd
import numpy as np
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score

# Argument Parsing
parser = argparse.ArgumentParser(description="Train a Random Forest classifier and save the model.")
parser.add_argument("-F", "--feature-file", type=str, required=True, help="Filename of extracted feature dataset (TSV format).")
parser.add_argument("-C", "--classifier-file", type=str, required=True, help="Filename to save the trained classifier as a pickle file.")
parser.add_argument("-T", "--training-statistics", type=str, help="Optional: Filename to save training statistics. If omitted, stats are printed to STDOUT.")
parser.add_argument("-I", "--importance-file", type=str, default="feature_importance.tsv", help="Filename to save feature importance scores.")
args = parser.parse_args()

# Print progress message to STDERR
sys.stderr.write(f"Loading extracted features from {args.feature_file}...\n")
sys.stderr.flush()

### **Fix: Extract the Correct Block from the TSV File**
with open(args.feature_file, "r") as f:
    lines = f.readlines()

# Find the block containing extracted features
feature_lines = []
inside_features_block = False

for line in lines:
    if "//" in line:  # End of a TSV block
        if inside_features_block:
            break  # Stop reading after the feature block ends
        inside_features_block = True  # Start reading the next block
    elif inside_features_block:
        feature_lines.append(line)

# Convert extracted feature lines to a DataFrame
from io import StringIO
feature_data = StringIO("".join(feature_lines))

sys.stderr.write("Parsing extracted features...\n")
sys.stderr.flush()

try:
    feature_df = pd.read_csv(feature_data, sep="\t")
except pd.errors.ParserError as e:
    sys.stderr.write(f"Error reading features file: {e}\n")
    sys.exit(1)

sys.stderr.write(f"Dataset loaded with {len(feature_df)} samples.\n")
sys.stderr.flush()

# Extract feature columns and labels
X = feature_df.drop(columns=["sampleID", "label"])  # Features
y = feature_df["label"]  # Labels (1 = disease, 0 = control)

sys.stderr.write("Splitting dataset into training (80%) and testing (20%)...\n")
sys.stderr.flush()

# Split into training (80%) and testing (20%) sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)

sys.stderr.write("Initializing Random Forest Classifier...\n")
sys.stderr.flush()

# Initialize Random Forest Classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight="balanced")

sys.stderr.write("Performing 5-fold cross-validation...\n")
sys.stderr.flush()

# Perform cross-validation (5-fold)
cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring="roc_auc")

sys.stderr.write(f"Cross-validation completed. Mean AUC: {np.mean(cv_scores):.4f}\n")
sys.stderr.flush()

sys.stderr.write("Training classifier on full training set...\n")
sys.stderr.flush()

# Train final model on full training set
clf.fit(X_train, y_train)

sys.stderr.write("Training completed. Evaluating on test set...\n")
sys.stderr.flush()

# Evaluate on test set
y_pred = clf.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)
test_auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])

sys.stderr.write(f"Test Accuracy: {test_accuracy:.4f}, Test AUC-ROC: {test_auc:.4f}\n")
sys.stderr.flush()

# Generate training statistics output
training_stats = (
    f"Cross-Validation AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\n"
    f"Test Accuracy: {test_accuracy:.4f}\n"
    f"Test AUC-ROC: {test_auc:.4f}\n"
)

# Save or print training statistics
if args.training_statistics:
    sys.stderr.write(f"Saving training statistics to {args.training_statistics}...\n")
    sys.stderr.flush()
    with open(args.training_statistics, "w") as f:
        f.write(training_stats)
else:
    sys.stdout.write(training_stats)

sys.stderr.write("Computing feature importance...\n")
sys.stderr.flush()

# Get feature importance scores from Random Forest
feature_importance = clf.feature_importances_
feature_names = X_train.columns

# Create DataFrame for feature importance
importance_df = pd.DataFrame({"Feature": feature_names, "Importance": feature_importance})

# Sort features by importance (descending)
importance_df = importance_df.sort_values(by="Importance", ascending=False)

# Save feature importance to file
importance_df.to_csv(args.importance_file, sep="\t", index=False)

sys.stderr.write(f"Feature importance saved to {args.importance_file}\n")
sys.stderr.flush()

# Print top 10 most important features to STDERR for quick debugging
sys.stderr.write("Top 10 Most Important Features:\n")
for _, row in importance_df.head(10).iterrows():
    sys.stderr.write(f"{row['Feature']}: {row['Importance']:.4f}\n")
sys.stderr.flush()

sys.stderr.write(f"Saving trained classifier to {args.classifier_file}...\n")
sys.stderr.flush()

# Save trained classifier model to a pickle file
with open(args.classifier_file, "wb") as f:
    pickle.dump(clf, f)

sys.stderr.write("Training complete! Model and statistics saved successfully.\n")
sys.stderr.flush()
